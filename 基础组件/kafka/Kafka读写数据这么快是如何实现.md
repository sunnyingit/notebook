Kafka 读写数据这么快是如何做到的？

## 顺序IO实现

kafka 在写数据的时是以「磁盘顺序写」的方式来进行落盘的, 即将数据追加到文件的末尾。

对于普通机械磁盘, 如果是随机写的话, 涉及到磁盘寻址的问题, 导致性能极低,  但是如果只是按照顺序的方式追加文件末尾的话, 这种磁盘顺序写的性能基本可以跟写内存的性能差不多的。

普通机械磁盘的顺序I/O性能指标是52M/s

## Page Cache

首先 Kafka 为了保证磁盘写入性能，通过 mmap 内存映射的方式利用操作系统的 Page Cache 异步写入 。也可以称为 os cache，意思就是操作系统自己管理的缓存。那么在写磁盘文件的时候，就可以先直接写入 os cache 中，接下来由操作系统自己决定什么时候把 os cache 里的数据真正刷入到磁盘中, 这样大大提高写入效率和性能。

避免了直接操作IO，减少了程序阻塞和上下文切换。


## 零拷贝技术

kafka 为了解决内核态和用户态数据不必要 Copy 这个问题, 在读取数据的时候就引入了「零拷贝技术」。即让操作系统的 os cache 中的数据直接发送到网卡后传出给下游的消费者，中间跳过了两次拷贝数据的步骤，从而减少拷贝的 CPU 开销, 减少用户态内核态的上下文切换次数,  从而优化数据传输的性能, 而Socket缓存中仅仅会拷贝一个描述符过去，不会拷贝数据到Socket缓存。

在 Kafka 中主要有以下两个地方使用到了「零拷贝技术」:

1. 基于 mmap 机制实现的索引文件：首先索引文件都是基于 MappedByBuffer 实现，即让用户态和内核态来共享内核态的数据缓冲区，此时数据不需要 Copy 到用户态空间。虽然 mmap 避免了不必要的 Copy，但是在不同操作系统下， 其创建和销毁成功是不一样的，不一定都能保证高性能。所以在 Kafka 中只有索引文件使用了 mmap。

2. 基于sendfile 机制实现的日志文件读写：在 Kafka 传输层接口中有个 TransportLayer 接口，它的实现类中有使用了 Java FileChannel 中 transferTo 方法。该方法底层就是使用 sendfile 实现的零拷贝机制， 目前只是在 I/O 通道是普通的 PLAINTEXT 的时候才会使用到零拷贝机制。


## 消息批量发送
Kafka 在发送消息的时候并不是一条条的发送的，而是会把多条消息合并成一个批次Batch 进行处理发送，消费消息也是同样，一次拉取一批次的消息进行消费。


## 数据压缩

Kafka 底层支持多种压缩算法: lz4,  snappy,  gzip,  从Kafka 2.1.0 开始新增了 ZStandard 算法, 该算法是 Facebook 开源的压缩算法,  能提供超高的压缩比。


在 Kafka 中, 压缩可能会发生在两个地方: 生产者端和Broker端。一句话总结下压缩和解压缩, 即 Producer 端压缩, Broker 端保持, Consumer 端解压缩，这样可以节省大量的网络和磁盘开销。
