# prometheus监控

## 基础概念梳理

### 样本（Sample）

在时间序列中的每一个点称为一个样本（sample），样本由以下三部分组成：
1. 指标 metric：指标名称和描述当前样本特征的 labelsets；
2. 时间戳 timestamp：一个精确到毫秒的时间戳；
3. 样本值 value：一个 float64 的浮点型数据表示当前样本的值。

### 时间序列

时间序列由指标名称 Metrics Name 以及一组标签（键值对）的唯一标识。其中指标的名称（metric name）可以反映被监控样本的含义，例如http_requests_total：表示当前系统接收到的 HTTP 请求总量。样本的数据反映了数据段内QPS的变化。

### 标签
对于相同的指标名称，通过不同标签列表的集合，会形成特定的度量维度实例。
比如记录http_requests_total这个指标的机房消息idc=SH, 记录http请求method http_method=GET，这里idc, http_method都是标签。

这样我们就指定特定机房下，http_method=GET的http_requests_total的值是多少。

### 指标类型
每个指标都必须有特定的数据类型，比如http_requests_total表示请求的总数，这个指标的特性是只增不减。
目前，prometheus支持四种指标

#### Counter
Counter类型代表一种样本数据单调递增的指标，即只增不减.


#### Gauge
Gauge 类型代表一种样本数据可以任意变化的指标，即可增可减。
Gauge 通常用于像温度或者内存使用率这种指标数据，也可以表示能随时增加或减少的“总数”，例如：当前并发请求的数量。

对于 Gauge 类型的监控指标，通过 PromQL 内置函数 delta() 可以获取样本在一段时间内的变化情况，例如，计算 CPU 温度在两小时内的差异：
dalta(cpu_temp_celsius{host="zeus"}[2h])
你还可以通过PromQL 内置函数 predict_linear() 基于简单线性回归的方式，对样本数据的变化趋势做出预测。例如，基于 2 小时的样本数据，来预测主机可用磁盘空间在 4 个小时之后的剩余情况：
predict_linear(node_filesystem_free{job="node"}[2h], 4 * 3600) < 0


#### Histogram
为了发现长尾问题（区分是平均的慢还是长尾的慢），最简单的方式就是按照请求延迟的范围进行分组。例如，统计延迟在 0~10ms 之间的请求数有多少而 10~20ms 之间的请求数又有多少。

通过这种方式可以快速分析系统慢的原因。Histogram 和 Summary 都是为了能够解决这样问题的存在，通过 Histogram 和 Summary 类型的监控指标，我们可以快速了解监控样本的分布情况。

Histogram 在一段时间范围内对数据进行采样（通常是请求持续时间或响应大小等），并将其计入可配置的存储桶（bucket）中，后续可通过指定区间筛选样本，也可以统计样本总数，最后一般将数据展示为直方图。

分位值：假设样本的 90% 分位数（quantile=0.9）的值为 x，即表示小于 x 的采样值的数量占总体采样值的90%。


#### Summary
与 Histogram 类型类似，用于表示一段时间内的数据采样结果（通常是请求持续时间或响应大小等），但它直接存储了分位数（通过客户端计算，然后展示出来），而不是通过区间来计算。


### PromQL
PromQL（Prometheus Query Language）是 Prometheus 内置的数据查询语言，它能实现对事件序列数据的查询、聚合、逻辑运算等。它并且被广泛应用在 Prometheus 的日常应用当中，包括对数据查询、可视化、告警处理当中。
简单地说，PromQL 广泛存在于以 Prometheus 为核心的监控体系中。所以需要用到数据筛选的地方，就会用到 PromQL。例如：监控指标的设置、报警指标的设置等等。

### 瞬时向量（instant vector）
一组时间序列，每个时间序列包含一个样本，所有样本共享相同的时间戳。也就是说这个某个时间点上所有样本的值。

### 区间向量（range vector）
一组时间序列，其中包含每个时间序列随时间变化的一系列数据点。


### 时序陈旧性
我们有时会看到某个时序已经停止了产生新样本，但是依然可以查询到它或者在视图上能看到样本，还有一个问题，新手在使用prometheus会很好奇，每次读取数据不一样，这跟Staleness有关。


运行查询时，由于多个聚合时间序列在时间上不完全对齐，为了支持聚合（sum、avg等）操作，相关的时序在计算时间点及之前一段时间内（默认配置5分钟）都是可选择/可见的。可以认为在当前时间点之前的一段时间（默认配置5分钟）仍能看到时序的样本，则时序是Normal状态，否则则是Stale状态。
Prometheus 使用 Stale 机制来标识那些已经不再变化了的 TimeSeries，当它被标记为stable or 在时间点之前的 5分钟(默认配置) 内找不到样本的话，在图表上它会立即消失。



## 基础篇


### 选择器
1. 瞬时向量选择：http_requests_total{}
2. 区间向量选择：http_requests_total{}[5m]

时间范围选择器支持其它时间单位：
1. s - 秒
2. m - 分钟
3. h - 小时
4. d - 天
5. w - 周
6. y - 年

### 匹配器
通过在花括号 ({}) 中附加逗号分隔的标签匹配器列表来进一步过滤这些时间序列。
比如：http_requests_total{env="prod", app=~"apiserver"} 
匹配符号包括：
1. =  (等式匹配)
2. !=  (不等式匹配)
3. =~ (正则匹配) 
4. !~  (非正则匹配)
5. 时间偏移（offset）

在瞬时向量表达式或者区间向量表达式中，都是以当前时间为基准：
1. 瞬时向量表达式，当前时间为基准: http_request_total{}
2.  区间向量表达式，选择以当前时间为基准，5分钟内的数据: http_request_total{}[5m]

而如果想查询，5分钟前的瞬时样本数据，或昨天一天的区间内的样本数据呢? 这个时候我们就可以使用位移操作，位移操作的关键字为offset。

可以使用offset时间位移操作：
1. http_request_total{} offset 5m
2. http_request_total{}[1d] offset 1d

请注意 offset 修饰符总是需要立即跟随选择器。

### 常用函数
rate: is the process of calculating the average per second rate of value increases
rate增长率 = 增长的总数 / 时间， 只有counter类型才会用到。
比如增长的数据如下
数据如下：
1 3 5 7 9
增长数据：
0 2 2 2
这段时间的增长率 =（2+2+2）/ 增长的时间

rate计算的是一组数据的每秒中的平均增长率，irate是一组数据最近两个数据之间的增长率，并忽略所有较早的样本;
irate = lastValue--previousValue /  两个点之间的时间消耗

sum：累计所有的值。
sum(rate(mysql_client_requests_duration_ms_count{app="$app",env="$env",addr=~"$addr",cluster=~"$cluster",command=~"$command"}[5m]))
累加增加率也就是说在app=$app, env=$env等标签内，5min时间段内的增长率之和，也就是说每秒钟增加率之和，换句话说就是每秒钟增加了多少请求；

by/without: 分组

without用于从计算结果中移除列举的标签，而保留其它标签。by则正好相反，结果向量中只保留列出的标签，其余标签则移除。通过without和by可以按照样本的问题对数据进行聚合。


### 关联计算

例如当存在样本：
、、、
method_code:http_errors:rate5m{method="get", code="500"}  24
method_code:http_errors:rate5m{method="get", code="404"}  30
method_code:http_errors:rate5m{method="put", code="501"}  3
method_code:http_errors:rate5m{method="post", code="500"} 6
method_code:http_errors:rate5m{method="post", code="404"} 21
method:http_requests:rate5m{method="get"}  600
method:http_requests:rate5m{method="del"}  34
method:http_requests:rate5m{method="post"} 120
、、、

计算：该表达式会返回在过去5分钟内，HTTP 请求状态码为500的在所有请求中的比例。

method_code:http_errors:rate5m{code="500"} / ignoring(code) method:http_requests:rate5m
结果如下：

、、、
{method="get"}  0.04            //  24 / 600
{method="post"} 0.05            //   6 / 120
、、、


常用的计算逻辑:

、、、
// 计算QPS, 以command为维度，不相同的command的增加率加起来(每一秒钟增加了多少)就是command维度的增加率。为什么要累加呢，因为这样计算出来的就是全局的qps(包括了所有机房，所有机器)
sum(rate(mysql_client_requests_duration_ms_count{app="$app",env="$env",addr=~"$addr",cluster=~"$cluster",command=~"$command"}[5m])) by (command)

// 计算出错的QPS
sum(irate(gorpc_client_requests_code_total{app=~"$app",env="$env",method!~".*Ping",code!="0"}[5m])) by (method,code)

、、、

API的平均响应时间 = 增加的响应时间 / 增加的qps
avg：在同一个机房，同一个env里，所有机器的平均时间，因此没有给出机器的lable。所以不考虑机器维度，最后按照API分组:
、、、
avg(increase(http_client_requests_duration_ms_sum{env="$env",app=~"$app",path!~".*/discovery/.*"}[5m])/ increase(http_client_requests_duration_ms_count{app=~"$app",env="$env",path!~".*/discovery/.*"}[5m]) > 0 ) by (path)
、、、


分位值
、、、
_metricReqDur = metric.NewHistogramVec(&metric.HistogramVecOpts{
		Namespace: namespace,
		Subsystem: "infoc2",
		Name:      "requests_duration_ms",
		Help:      "log infoc2 client requests duration(ms).",
		Labels:    []string{"log_id"},
		Buckets:   []float64{5, 10, 25, 50, 100, 250, 500, 1000, 2500, 5000, 10000, 25000, 50000},
	})

histogram_quantile(0.99, sum by (command, le) (rate(redis_client_requests_duration_ms_bucket{env="$env",app=~"$app",cluster=~"$cluster"}[5m])))
、、、
