限流算法

## token bucket算法

思路是向bucket里面以以恒定的速度生产tokens，主要过程如下：

1. A token is added to the bucket every 1/r seconds
2. The bucket can hold at the most b tokens. If a token arrives when the bucket is full, it is discarded
3. When a packet (network layer PDU) of n bytes arrives:
4. if at least n tokens are in the bucket, n tokens are removed from the bucket, and the packet is sent to the network
5. if fewer than n tokens are available, no tokens are removed from the bucket, and the packet is considered to be non-conformant

packet可以理解为一次请求，每次请求都像bucket申请一个token，如果bucket里面没有token了则丢弃该请求。

实现需要以每秒钟生成tokens数，有两种方法：

1. 后台有个线程每 1/n 秒将 bucket 中的 token 数量加一，直至达到 bucket 容量。
这种方法有一个很大的缺点，那就是因为每个 token bucket 都会有一个繁忙的后台线程在更新 token 数量，会 导致严重占用系统 CPU 出现严重的性能问题。假设我们的限速是限制为 1000/s，此时后台每隔 1ms 就会更新一次 token 数量，可以想像每个后台线程都会频繁占用 CPU，用这种方法实现的 rate limiting 处理不了几个请求就会出现 CPU 接近 100% 的情况。

2. 在取 token 时计算上次取跟这次取之间按照速率会产生多少个 token 加上上次剩余的 token （不能超过 bucket 容量限制），然后比较剩余 token 数是否满足需要。(推荐)

实现代码如下：
、、、
type Limiter struct {
	// 频率：每秒钟生成token的个数
	limit Limit

	// 爆满：tokens个数的上限
	burst int

	// 互斥锁，更新limit, burst都会用到
	mu     sync.Mutex

	// 当前存在tokens的个数
	tokens float64

	// 上一次tokens值更新的时间
	last time.Time

    // lastEvent is the latest time of a rate-limited event (past or future)
	lastEvent time.Time
	// ?
    update    chan interface{}
}

// A Reservation holds information about events that are permitted by a Limiter to happen after a delay.
// A Reservation may be canceled, which may enable the Limiter to permit additional events.
// Reservation是调用了限流函数的返回值，保留了限流的返回消息
type Reservation struct {
	ok        bool
	lim       *Limiter
	tokens    int
	timeToAct time.Time
	// 开始时间
	now time.Time
	// This is the Limit at reservation time, it can change later.
	limit Limit
}

func (lim *Limiter) reserveN(now time.Time, n int, maxFutureReserve time.Duration) Reservation {
	// 涉及到limiter的属性tokens更新，所以要加互斥锁
	lim.mu.Lock()

	// limit==Inf 表示不设限
	if lim.limit == Inf {
		lim.mu.Unlock()
		return Reservation{
			ok:        true,
			lim:       lim,
			tokens:    n,
			timeToAct: now,
		}
	}
	// limit为0 一直sleep 等待
	if lim.limit == 0 {
		lim.mu.Unlock()
		return Reservation{
			ok:        false,
			lim:       lim,
			tokens:    0,
			timeToAct: maxTime,
			limit:     0,
		}
	}

 	// 截至 now 时间时，可以获取的令牌 tokens 数量及上一次拿走令牌的时间 last
	// 就是tokens方法二实现的算法
	now, last, tokens := lim.advance(now)

	var oldTokens = tokens
	// 计算：当前的token-需要申请的tokens
	tokens -= float64(n)

	// 如果tokens为负数，说明当前tokens不满足需要申请的数
    // 需要计算申请剩余的数需要多长时间
	var waitDuration time.Duration
	if tokens < 0 {
		waitDuration = lim.limit.durationFromTokens(-tokens)
	}

	// ok: true表示满足条件， false表示不满足
    // 条件是: n小于tokens的上线，waitDuration小于预期等待的时间，如果waitDuration参数传递是0，则表示不等待;
	ok := n <= lim.burst && waitDuration <= maxFutureReserve

	// Prepare reservation
	r := Reservation{
		ok:    ok,
		lim:   lim,
		limit: lim.limit,
	}

	// 如果tokens为负数，说明当前tokens不满足需要申请的数
	if tokens < 0 {
		// 开始的时间往后延迟点？？
		r.now = now.Add(lim.limit.durationFromTokens(-oldTokens))
	}
	if ok {
		r.tokens = n
		// 满足tokens个数需要等待的时间
		r.timeToAct = now.Add(waitDuration)
	}

	// 修改limiter的属性
	if ok {
		lim.last = now
		lim.tokens = tokens
		lim.lastEvent = r.timeToAct
	} else {
		lim.last = last
	}

    lim.mu.Unlock()
	return r
}

// 前进到now的时刻 会有多少tokens
func (lim *Limiter) advance(now time.Time) (newNow time.Time, newLast time.Time, newTokens float64) {
	last := lim.last
	if now.Before(last) {
		last = now
	}

	// Avoid making delta overflow below when last is very old.
	maxElapsed := lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens)
	elapsed := now.Sub(last)
	if elapsed > maxElapsed {
		elapsed = maxElapsed
	}

	// Calculate the new number of tokens, due to time that passed.
	delta := lim.limit.tokensFromDuration(elapsed)
	tokens := lim.tokens + delta
	if burst := float64(lim.burst); tokens > burst {
		tokens = burst
	}

	return now, last, tokens
}

// 需要生成的token总数是tokens， 频率是limit; 需要的时间=tokens / float64(limit)，单位换成了纳秒
func (limit Limit) durationFromTokens(tokens float64) time.Duration {
	seconds := tokens / float64(limit)
	return time.Nanosecond * time.Duration(1e9*seconds)
}

// d时间内产生的tokens的数量
func (limit Limit) tokensFromDuration(d time.Duration) float64 {
	// Split the integer and fractional parts ourself to minimize rounding errors.
	// See golang.org/issues/34861.
	sec := float64(d/time.Second) * float64(limit)
	nsec := float64(d%time.Second) * float64(limit)
	return sec + nsec/1e9
}

、、、


非阻塞的使用：

、、、
r := lim.ReserveN(time.Now(), 1)
if !r.ok() {
    // Not allowed to act! Did you remember to set lim.burst to be > 0 ?
   return
}
time.Sleep(r.Delay())
Act()
、、、


## Leaky bucket 算法
漏桶算法思路很简单，水（请求）先进入到漏桶里(队列中)，漏桶以一定的速度出水(消费端以恒定的速率消费)，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。这种算法可以应对突然流量场景，比如秒杀等。

1. 无法动态调整桶的大小。
2. 无法精确控制处理速度。

实现[uber limiter](!https://github.com/uber-go/ratelimit)


## 算法对比


令牌桶的“突发流量”跟我们通常理解的“业务高并发”并不一样。
令牌桶的算法原本是用于网络设备控制传输速度的，而且它控制的目的是保证一段时间内的平均速率控制，之所以说令牌桶适合突发流量，是指在网络传输的时候，可以允许某段时间内（一般就几秒）超过平均传输速率，这在网络环境下常见的情况就是“网络抖动”，但这个短时间的突发流量是不会导致雪崩效应，网络设备也能够处理得过来。

对应到令牌桶应用到业务处理的场景，就要求即使有突发流量来了，系统自己或者下游系统要真的能够处理的过来，否则令牌桶允许突发流量进来，结果系统或者下游处理不了，那还是会被压垮。

而我说漏桶算法更适合“突发流量”，是指秒杀、抢购、整点打卡签到、微博热点事件这种业务高并发场景，它不是由于“XX 抖动”引起的，而是由业务场景引起的，并且持续的事件可能是几分钟甚至几十分钟，这种业务场景为了用户体验和业务尽量少受损，优先采取的不是丢弃大量请求，而是缓存请求，避免系统出现雪崩效应。因此我们会看到，漏桶和令牌桶都有保护作用，但漏桶的保护是尽量缓存请求（缓存不下才丢），令牌桶的保护主要是丢弃请求（即使系统还能处理，只要超过指定的速率就丢弃，除非此时动态提高速率）。

所以如果在秒杀、抢购、整点打卡签到、微博热点事件这些业务场景用令牌桶的话，会出现大量用户访问出错，因为请求被直接丢弃了；而用漏桶的话，处理可能只是会慢一些，用户体验会更好一些，所以我认为漏桶更适合“突发流量”。
