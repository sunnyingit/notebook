一致性和可用性的分析

## 高可用

首先，我们需要理解什么是高可用， 需要做好如下的设计：


1. 对软硬件的冗余，以消除单点故障。任何系统都会有一个或多个冗余系统做standby
2. 对故障的检测和恢复，检测故障以及用备份的结点接管故障点。这也就是failover
3. 需要很可靠的交汇点（CrossOver）。这是一些不容易冗余的结点，比如域名解析，负载均衡器等。

听起似乎很简单吧，然而不是，细节之处全是魔鬼，冗余结点最大的难题就是对于有状态的结点的数据复制和数据一致性的保证（无状态结点的冗余相对比较简单）。冗余数据所带来的一致性问题是魔鬼中的魔鬼：

如果系统的数据镜像到冗余结点是异步的，那么在failover的时候就会出现数据差异的情况。
如果系统在数据镜像到冗余结点是同步的，那么就会导致冗余结点越多性能越慢。

下面，总结一下高可用的设计原理：

要做到数据不丢，就必需要持久化
要做到服务高可用，就必需要有备用（复本），无论是应用结点还是数据结点
要做到复制，就会有数据一致性的问题。
我们不可能做到100%的高可用，也就是说，我们能做到几个9个的SLA。

比如，99.999%的可用性，一年只能有5分半钟的服务不可用。感觉很难做到吧。

就算是3个9的可用性，一个月的宕机时间也只有40多分钟，看看那些设计和编码不认真的团队，把所有的期望寄托在人肉处理故障的运维团队， 一个故障就能处理1个多小时甚至2-3个小时，连个自动化的工具都没有，还好意思在官网上声明自己的SLA是3个9或是5个9，这不是欺骗大众吗？。

真正决定高可用系统的本质原因如下：
1. 软件的设计、编码、测试、上线和软件配置管理的水平
2. 工程师的人员技能水平
3. 运维的管理和技术水平
4. 数据中心的运营管理水平
5. 依赖于第三方服务的管理水平


为了避免单点问题, 我们需要部署多个实例，如果实例是有状态的实例，例如mysql等，各个实例之间需要同步，来保证数据的一致性。

如何实现主备强一致？大家都知道数据库中最重要的一个技术：WAL（Write-Ahead-Logging）。更新操作写日志（Oracle Redo Log，MySQL Binlog等），事务提交时，保证将事务产生的日志先刷到磁盘上，保证整个事务的更新操作数据不丢失。那实现数据库主备数据强一致的方法也很简单：
1. 事务提交的时候，同时发起两个写日志操作，一个是将日志写到本地磁盘的操作，另一个是将日志同步到备库并且确保落盘的操作；
2. 主库此时等待两个操作全部成功返回之后，才返回给应用方，事务提交成功；

由于事务提交操作返回给应用时，事务产生的日志在主备两个数据库上都已经存在了，强同步。

因此，此时主库Crash的话，备库提供服务，其数据与主库是一致的，没有任何事务的数据丢失问题。主备数据强一致实现。

实现数据的强同步实现之后，接下来到了考虑可用性问题。现在已经有主备两个数据完全一致的数据库，备库存在的主要意义，就是在主库出故障时，能够接管应用的请求，确保整个数据库能够持续的提供服务：主库Crash，备库提升为主库，对外提供服务。

此时，又涉及到一个决策的问题，主备切换这个操作谁来做？人当然可以做，接收到主库崩溃的报警，手动将备库切换为主库。但是，手动的效率是低下的，更别提数据库可能会随时崩溃，全部让人来处理，也不够厚道。一个HA（High Availability）检测工具应运而生：HA工具一般部署在第三台服务器上，同时连接主备，当其检测到主库无法连接，就切换备库，很简单的处理逻辑：

1. HA软件与主备同时连接，并且有定时的心跳检测。主库Crash后，HA探测到，发起一个将备库提升为主库的操作（修改备库的VIP或者是DNS，可能还需要将备库激活等一系列操作），新的主库提供对外服务。此时，由于主备的数据是通过日志强同步的，因此并没有数据丢失，数据一致性得到了保障。

首先，一个一目了然的问题，主库Crash，备库提升为主库之后，此时的数据库是一个单点，原主库重启的这段时间，单点问题一直存在。如果这个时候，新的存储再次Crash，整个系统就处于不可用状态。此问题，可以通过增加更多副本，更多备库的方式解决，例如3副本（一主两备），此处略过不表。

其次，在主备环境下，处理主库挂的问题，算是比较简单的，决策简单：主库Crash，切换备库。但是，如果不是主库Crash，而是网络发生了一些问题。

还有，如果Master与Slave之间的网络出现问题，例如：断网，网络抖动等。此时数据库应该怎么办？Master继续提供服务？Slave没有同步日志，会数据丢失。Master不提供服务？应用不可用。在Oracle中，如果设置为 最大可用 模式，则此时仍旧提供服务，允许数据不一致；如果设置为 最大保护 模式，则Master不提供服务。因此，在Oracle中，如果设置为 最大保护 模式，一般建议设置两个或以上的Slave，任何一个Slave日志同步成功，Master就继续提供服务，提供系统的可用性。


HA与Master之间的网络出现问题，此时HA面临两个抉择：
HA到Master之间的连接不通，认为主库Crash。选择将备库提升为主库。但实际上，只是HA到Master间的网络有问题，原主库是好的（没有被降级为备库，或者是关闭），仍旧能够对外提供服务。新的主库也可以对外提供服务。两个主库，产生双写问题，最为严重的问题。
HA到Master之间的连接不通，认为是网络问题，主库未Crash。HA选择不做任何操作。但是，如果这时确实是主库Crash了，HA不做操作，数据库不对外提供服务。双写问题避免了，但是应用的可用性受到了影响。
最后，数据库会出现问题，数据库之间的网络会出现问题，那么再考虑一层，HA软件本身也有可能出现问题

如果是HA软件本身出现了问题，怎么办？我们通过部署HA，来保证数据库系统在各种场景下的持续可用，但是HA本身的持续可用谁来保证？难道我们需要为HA做主备，然后再HA之上再做另一层HA？


## 分区可用性

，再回顾一下上一节新引入的三个问题：
1. HA软件自身的可用性如何保证？
2. 如果HA软件无法访问主库，那么这时到底是主库Crash了呢？还是HA软件到主库间的网络出现问题了呢？如何确保不会同时出现两个主库，不会出现双写问题？
3. 如何在解决上面两个问题的同时，保证数据库的持续可用？

解决方案：
1. 原来的一台HA主机，扩展到了3台HA主机。一台是HA Master，其余的为HA Participant；
2. 数据库上面分别部署了HA Client；
3. HA主机与HA Client进行双向通讯。HA主机需要探测HA Client所在的DB是否能够提供服务，这个跟原有一致。但是，新增了一条HA Client到HA主机的Master Lease通讯。


这些变化，能够解决上面的两个问题吗？让我们一个一个来分析。首先是：HA软件自身的可用性如何保证？
从一台HA主机，增加到3台HA主机，正是为了解决这个问题。HA服务，本身是无状态的，3台HA主机，可以通过Paxos/Raft进行自动选主。选主的逻辑，我这里就不做赘述，不是本文的重点，想详细了解其实现的，可以参考互联网上洋洋洒洒的关于Paxos/Raft的相关文章。总之，通过部署3台HA主机，并且引入Paxos/Raft协议，HA服务的高可用可以解决。HA软件的可用性得到了保障。


第二个问题，可以细分为三个场景：
场景一：主库Crash，但是主库所在的服务器正常运行，HA Client运行正常
主库Crash，HA Client正常运行。这种场景下，HA Client向HA Master发送一个放弃主库租约的请求，HA Master收到请求，直接将备库提升为主库即可。原主库起来之后，作为备库运行。
场景二：主库所在的主机Crash。（主库和HA Client同时Crash）
此时，由于HA Client和主库同时Crash，HA Master到HA Client间的通讯失败。这个时候，HA Master还不能立即将备库提升为主库，因为区分不出场景二和接下来的场景三（网络问题）。因此，HA Master会等待超过租约的时间（例如：12秒），如果租约时间之内仍旧没有续租的消息。那么HA Master将备库提升为主库，对外提供服务。原主库所在的主机重启之后，以备库的状态运行。

场景三：主库正常，但是主库到HA Master间的网络出现问题

对于HA Master来说，是区分不出场景二和场景三的。因此，HA Master会以处理场景二同样的逻辑处理场景三。等待超过租约的时间，没有收到续租的消息，提升原备库为主库。但是在提升备库之前，原主库所在的HA Client需要做额外的一点事。原主库HA Client发送给HA Master的续租请求，由于网络问题，一直没有得到响应，超过租约时间，主动将本地的主库降级为备库。如此一来，待HA Master将原备库提升为主库时，原来的主库已经被HA Client降级为备库。双主的情况被杜绝，应用不可能产生双写。
通过以上三个场景的分析，问题二同样在这个架构下被解决了。而解决问题二的过程中，系统最多需要等待租约设定的时间，如果租约设定为10秒，那么出各种问题，数据库停服的时间最多为10秒，基本上做到了持续可用。这个停服的时间，完全取决于租约的时间设置。
到这儿基本可以说，要实现一个持续可用（分区可用性保证），并且保证主备数据强一致的数据库系统，是完全没问题的

## 性能

为了保证数据强同步，应用发起提交事务的请求时，必须将事务日志同步到Slave，并且落盘。相对于异步写Slave，同步方式多了一次Master到Slave的网络交互，同时多了一次Slave上的磁盘sync操作。反应到应用层面，一次Commit的时间一定是增加了，具体增加了多少，要看主库到备库的网络延时和备库的磁盘性能。
为了提高性能，第一个很简单的想法，就是部署多个Slave，只要有一个Slave的日志同步完成返回，加上本地的Master日志也已经落盘，提交操作就可以返回了。多个Slave的部署，对于消除瞬时的网络抖动，非常有效果。

新增一个Slave，数据三副本。两个Slave，只要有一个Slave日志同步完成，事务就可以提交，极大地减少了某一个网络抖动造成的影响。增加了一个副本之后，还能够解决当主库Crash之后的数据安全性问题，哪怕主库Crash，仍旧有两个副本可以提供服务，不会形成单点。
但是，在引入数据三副本之后，也新引入了一个问题：主库Crash的时候，到底选择哪一个备库作为新的主库？当然，选主的权利仍旧是HA Master来行使，但是HA Master该如何选择？这个问题的简单解决可以使用下面的几个判断标准：
日志优先。两个Slave，哪个Slave拥有最新的日志，则选择这个Slave作为新的主库。
主机层面排定优先级。如果两个Slave同时拥有最新的日志，那么该如何选择？此时，选择任何一个都是可以的。例如：可以根据Slave主机IP的大小进行选择，选择IP小的Slave作为新的主库。同样能够解决问题。
