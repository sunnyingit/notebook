# 编码一点通


## 前述
在解释编码之前，我们需要清楚几个基础概念：

1. bit: 比特，简单的说就是0和1。
2. byte: 字节，8个bit构成一个字节，字节是计算机最小的存储单位，比如某个东西只占用1个bit，那我们也用一个字节大小的单位存储它。
3. byte stream: 字节流 多个字节称之为字节流。
4. character: 字符，比如英文字母，汉字之类。
5. string: 字符串，多个字符称之为字符串。

> 字节流的本质就是一串0和1，并没有任何意义。但我们需要赋予字节流意义，比如让一段字节流表示为`hello world`，这就需要编码。

编码实现了字节流和字符之间的相互转换：
1. 当我们要存储字符到计算机：把字符转成字节流，这个过程叫做编码。
2. 当我们要从计算机读取字符：把字节流转成字符，这个过程叫做解码。

不仅仅是字符，包括图片，视频，声音等，它们储存到计算机时都需要相应的编码过程，从计算机读出来翻译成字符，图片，视频时，需要解码。

## 编码原理
为了让字节流和字符之间能相互转换，我们需要一张编码字符集，规定字符到字节流的对应关系。
编码字符集目前有多个，其中我们熟知的就有`ASCII`，`GB2312/GBK/GB18030`, `Unicode`, 注意并没有`UTF-8`。

## ASCII
一个字节有8个bit，每个bit有0、1两种状态，因此1字节可以组合出2的8次方一共256种状态。
`ASCII`用一个字节来表示128个字符。`ASCII`规定的字符包括英文字母A-Z，a-z，数字0-9，一些标点符号和控制符号等。

例如:
| 二进制 | 十进制 | 十六机制 | 字符 |
| ----------- | ----------- | ----------- | ----------- |
|0110 0001 | 97  | 61 | a |
|0111 1111 | 127 | 7F | DEL字符 |

说的直白一点，字符a存储到计算机的字节流是`0110 0001`，用10进制表示是`97`，用16进制表示是`61`。

Go语言可以使用`Printf`输出:

```
func main() {
	s := "a"

	// 打印s在计算机内部的字节
	fmt.Printf("2进制:%.8b\n", []byte(s))

	// 字节10进制表示方式
	fmt.Printf("10进制:%d\n", []byte(s))

	// 字节的16进制表示
	fmt.Printf("16进制:%x\n", []byte(s))
}

// 输出：
// 2进制:[01100001]
// 10进制:[97]
// 16进制:61
```

`ASCII`最后一个字符是`\x7F`，也就是说大于`\x7F`都不是`ASCII`字符，我们可以根据这个特性判断字符是否是`ASCII`。


## GBK
对于英文国家来说，`ASCII`已经够了，但我们国家有几万个汉字，`ASCII`远远不够，于是我们搞出了GB2312/GBK/GB18030 三套编码。

它们三者之间的关系是：GB18030是GBK的扩展，GBK是GB2312的扩展。

GBK使用2个字节的固定长度来表示一个汉字。

## Unicode

不同国家的编码各不相同，那计算机把字节流转成字符时就会出现乱码。

为了解决这个问题，美国人又搞出了一套Unicode字符集。

Unicode将全世界所有的字符包含在一个集合里，计算机只要支持这一个字符集，就能显示所有的字符，再也不会有乱码了。

比如Unicode字符集规定`U+4E25`表示汉字"严"，`U+4E25`是Unicode的码点。

```
func main() {
	s := "严"
	fmt.Printf("Unicode:%U\n", []rune(s))
	fmt.Printf("2进制:%.8b\n", []byte(s))
	fmt.Printf("10进制:%d\n", []byte(s))
	fmt.Printf("16进制:%x\n", []byte(s))
}
// 输出:
// Unicode:[U+4E25]
// 2进制:[11100100 10111000 10100101]
// 10进制:[228 184 165]
// 16进制:e4b8a5

```

所谓编码和解码，就是`字节流`，`码点`，`字符`三者之间转换过程。

> 编码：字符转成对应的码点，码点换算成字节流。
> 解码：字节流转换为码点，码点转换对应的字符。


汉字"严"的unicode是十六进制数`4E25`，转换成二进制数有15位`[100 1110 0010 0101]`, 而我们打印的二进制是`[11100100 10111000 10100101]`。
为什么码点和实际存储在计算机的字节流不一样呢，这就是涉及到另外一个问题：Unicode码点的存储。

像`ASCII`，`GBK`是固定字节长度的编码，`ASCII`以一个字节长度存储码点，`GBK`以两个字节长度存储码点。

编码的时候，直接把字符对应的码点换算成字节流。
解码的时候，计算机读取固定长度的字节数，再查询编码字符集，找到字节流对应的字符。

但`Unicode`不一样，它没有规定字符的长度，也就是说，计算机并不知道需要读取几个字节数才能转成一个unicode码点对应的字符。

换句话说，在存储Unicode的字符时，我们需要知道字符的长度，如何存储Unicode码点，这就是`UTF-8`的工作。

## UTF-8

为了解决Unicode存储的问题，就发明了UTF-8编码。也就是说，UTF-8编码规定了Unicode的码点如何存储。

UTF-8使用1到4个字节表示一个字符，根据字符的不同变换长度。编码规则如下:

对于单个字节的字符，第一位设为0，后面的7位对应这个字符的`Unicode`码点。

因此，对于英文中的[0 - 127]号字符，与`ASCII`码完全相同。这意味UTF-8编码可以完全兼容ASCII。

对于需要使用 N 个字节来表示的字符（N > 1），第一个字节的前 N 位都设为 1，第 N + 1 位设为 0，剩余的 N - 1 个字节的前两位都设位 10，剩下的二进制位则使用这个字符的 Unicode 码点来填充。

编码规则如下:
|Unicode 十六进制码点范围 |	UTF-8 二进制|
| ----------- | ----------- |
|0000 0000 - 0000 007F|	 0xxxxxxx|
|0000 0080 - 0000 07FF|	 110xxxxx 10xxxxxx|
|0000 0800 - 0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx|
|0001 0000 - 0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx|


已知【严】的unicode是`4E25` [100 1110 0010 0101]，根据上表，可以发现`4E25`处在第三行的范围内[0000 0800 - 0000 FFFF]

因此"严"的UTF-8编码需要三个字节，即格式是"1110xxxx 10xxxxxx 10xxxxxx"。然后，从"严"的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。
这样就得到了，"严"的UTF-8编码是"11100100 10111000 10100101"，转换成十六进制就是`E4B8A5`。

```
func main() {
	s := "严"
	fmt.Printf("Unicode:%U\n", []rune(s))
	fmt.Printf("2进制:%.8b\n", []byte(s))
	fmt.Printf("10进制:%d\n", []byte(s))
	fmt.Printf("16进制:%x\n", []byte(s))
}

// 输出:
// Unicode:[U+4E25]
// 2进制:[11100100 10111000 10100101]
// 10进制:[228 184 165]
// 16进制:e4b8a5
```

>再次注意：Unicode编码是指字符的码点，UTF-8编码指的是字符在计算机中存储的byte流，一般用16进制的字符串表示， 例如"严"的Unicode的码点是`U+4E25`, UTF-8编码是`e4b8a5`。


## 解码和乱码
当我们读取文件字节流，网络字节流，处理json时，首先要做的事情就是指定字节流的【存储】编码。
比如一段字节流[11100100 10111000 10100101]，假设指定为utf-8编码。

计算机读取到第一个字节[11100100]，根据UTF-8的编码规则，有3个1表示3个字节拼成一个字符串，于是把后面两个字符组合在一起转成unicode编码[100111000100101]。
换成16进制，表示为`4E25`，在查一下unicode编码就发现了字符是“严”。

如果查询Unicode编码表，无法找到对应的字符，就会出现乱码。

所以解码前的第一件事情，是确认字节流的编码，假设`[11100100 10111000 10100101]`指定为GBK编码，这样解码就乱码了。


## 码点和字节字符串

码点和字节字符串都是特殊的字符串。

Go语言使用`\u`表示这是一个Unicode【码点】，使用`\x`表示字【字节】，这两类字符串和普通字符串有非常大的区别， Go程序读到类似的字符串时，会特殊处理：

```
func main() {
	// 码点
	s := "\u4E25"

    // 字节字符串
    b := "\xe4\xb8\xa5"

    // 普通字符串
	a := "u4E25"

	fmt.Printf("对应字符是:%s\n", s)
    fmt.Printf("对应字符是:%s\n", b)
	fmt.Printf("普通字符串:%s\n", a)
}

// 输出：
// 对应字符是:严
// 对应字符是:严
// 普通字符串:u4E25
```

我们详细解析下`\xe4\xb8\xa5`到“严”的过程：
Go程序读到`\xe4\xb8\xa5`后，因为有`\x`修辞，判定它是一个字节字符串，换成字节流是[11100100 10111000 10100101]，Go是utf8编码，所以通过utf8编码的规则解析,
第一个字节[11100100]有3个1，所以读取三个字节，然后在转成Unicode码点[u4E25], 对应的字符是[严]。

再来看一个例子：
文件`test.file`，其内容为`\xe4\xb8\xa5`, 使用golang读取这个文件，打印`\xe4\xb8\xa5`，那是否会输出"严"字呢

```
func main() {
	fd, _ := os.OpenFile("test.file", os.O_RDONLY, 0666)
	defer fd.Close()

	br := bufio.NewReader(fd)
	rawText := "\xe4\xb8\xa5"
	for {
		line, _, err := br.ReadLine()

		if err == io.EOF {
			break
		}

		fmt.Printf("文件读取行输出:%s, %.8b \n局部变量输出:%s, %.8b", line, []byte(line), rawText, []byte(rawText))
	}
}

// 输出内容：
// 文件读取行输出:\xe4\xb8\xa5, [01011100 01111000 01100101 00110100 01011100 01111000 01100010 00111000 01011100 01111000 01100001 00110101], 其中[01011100]对应字符"\"

// 局部变量输出:严, [11100100 10111000 10100101]
```

可以看出，golang读取文件行，读到`\xe4\xb8\xa5`后，只是把它当作普通字符串，而临时变量`rawText`则当作[节字]字符串。

总结一下：
1. 普通字符串: 保存的是字符，存储到计算机时，根据编码字符集把字符转换成对应码点，然后把码点换算成存储编码，最后把存储编码换成字节流。
2. 字节字符串: 存储到计算机时，直接把字节转换为字节流存储。
3. Unicode码点字符串：存储到计算机时, 把码点换算成对应的存储编码，然后把存储编码换成字节流。


## Go与编码

当我们遍历字符串时，我们期望的是按照字符遍历，而不是字节。如果字符由两个字节组成，如果遍历字节就会出问题。

这种情况，需要把字符串换成`[]rune`, `rune`保存的是Unicode的码点(10进制值)。这样遍历的是字符而非字节了。

```
first := "严格"
// 输出第一个字节
fmt.Println(first[0])

// 换成rune数组，rune保存的字符串的unicode码点
fmt.Println([]rune(first))

// 字节数组
fmt.Println([]byte(first))

// 输出:
// 228
// [20005 26684]
// [228 184 165 230 160 188]

```

go的`unicode`包提供了大量操作`rune`的方法，常用的如下:

```
func IsControl(r rune) bool  // 是否控制字符
func IsPunct(r rune) bool // 是否标点符号
func IsSpace(r rune) bool // 是否空格
func IsGraphic(r rune) bool // 是否图形字符
func IsPrint(r rune) bool // 是否可打印字符
func IsSymbol(r rune) bool // 是否符号字符
func IsTitle(r rune) bool // 是否 title case
func IsUpper(r rune) bool // 是否大写字符
```

我们可以利用这些函数判断是否为特殊字符，从而过滤相关字符。

go的`utf-8`也提供了相关函:
```
// 判断字节是否能组成一个合法的码点
func Valid(p []byte) bool

// 判断rune是否是合法的码点
func ValidRune(r rune) bool
```

在Go语言中，如果出现一个无效的码点，则会把这个码点转换成`EFBFBD`, 显示为「�」。

如果出现这种情况，一定是处理字符串不是UTF8编码，需要转换成UTF-8之后再做处理。

`GBK`和`UTF-8`相互转换：
```
func Utf82Gbk(s string) (string, error) {
	checker := func(r rune) rune {
		if r == utf8.RuneError {
			return -1
		}
		return r
	}
	s = strings.Map(checker, s)

	reader := transform.NewReader(bytes.NewReader([]byte(s)), simplifiedchinese.GBK.NewEncoder())
	d, e := ioutil.ReadAll(reader)
	if e != nil {
		return "", e
	}
	return string(d), nil
}

func Gbk2Utf8(s string) (string, error) {
	reader := transform.NewReader(bytes.NewReader([]byte(s)), simplifiedchinese.GBK.NewDecoder())
	d, e := ioutil.ReadAll(reader)
	if e != nil {
		return "", e
	}

	return string(d), nil
}
```

有些情况下，你需要把非ASCII字符转换成unicode码点字符串，例如`严`转成`u4E25`字符串存储到文件中，这种情况可以使用函数`QuoteToASCII`。

`QuoteToASCII`可以把非ASCII字符转成对应的码点表示：
```
str := strconv.QuoteToASCII(`"世界你好。♥ Welcome hello ♥"`)
fmt.Println(str)
// 输出：
// "\"\u4e16\u754c\u4f60\u597d\u3002\u2665 Welcome hello \u2665\""
```

`Unquote`可以码点字符串转化成对应的字符
```
func main() {
	fmt.Println(strconv.Unquote(`"Go\u2665\u4E25"`))
}
// 输出：Go♥严 <nil>
```

## python与编码
python内部使用Unicode编码，这意味着python处理字节流之前，必须保证输入的字节流是`Unicode`编码，否则就会出现乱码。

python处理完成后，如果需要把字节流写入到文件之类的操作，需要把`Unicode`编码为指定编码。

切记！

python提供两个函数：
 1. encode：从unicode编码为指定编码方式。例如：string.encode("utf-8")。表示string从unicode编码方式编码为utf-8编码方式。
 2. 从指定编码方式解码为unicode方式。string.decode("utf-8")。表示string从utf-8编码方式解码为unicode编码方式。

python使用`json.dumps`生成json，会自动把非`ASCII`的字符转成`ASCII`字符，例如`严`转成`u4E25`, 这样其他程序在load这个json文件时，会把`u4E25`当作普通字符，从而无法解析。

正确做法加入`ensure_ascii=False`参数：
```
In [75]: a = {"name":"中文"}

// 默认中文转成普通字符串
In [76]: json.dumps(a)
Out[76]: '{"name": "\\u4e2d\\u6587"}'

// 写入的是原字节流
In [77]: json.dumps(a, ensure_ascii=False)
Out[77]: '{"name": "\xe4\xb8\xad\xe6\x96\x87"}'
```

## json与双引号
```

```

## 总结
1. 编码是指字节和字符之间的转换。
2. ASCII, GBK, Unicode是编码字符集，而UTF-8只是一种规则用来存储Unicode码点。
3. 理解Unicode码点和UTF-8编码相互转换的过程。
4. 理解普通字符串，码点，字节字符串之间的区别。
5. Go默认是UTF-8编码，Python默认是Unicode编码。
